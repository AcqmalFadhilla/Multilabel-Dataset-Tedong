{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras as K\n",
    "import matplotlib.cm as cm\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from keras.callbacks import TensorBoard\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/label.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat daftar unique dari semua label\n",
    "unique_label = set()\n",
    "for label in df[\"Label\"]:\n",
    "    label_list = label.strip(\"[]\").split(\",\")\n",
    "    for label in label_list:\n",
    "        unique_label.add(label.strip())\n",
    "\n",
    "unique_label = sorted(list(unique_label))\n",
    "# buatkan kolom one-hot encodinf setiap label\n",
    "for label in unique_label:\n",
    "    df[label] = df[\"Label\"].apply(lambda x: int(label in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Filename\"] = \"data/image/\" + df[\"Filename\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, len(df), 10)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(10, 10),\n",
    "                    subplot_kw={'xticks': [], 'yticks': []})\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(df.Filename[random_index[i]]))\n",
    "    ax.set_title(df.Label[random_index[i]])\n",
    "fig.suptitle(\"Tedong Multilabel\", fontsize=16)\n",
    "plt.show()\n",
    "fig.savefig(\"tedong.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns='Label', axis=1, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=\"Label\", axis=1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns=\"Label\", axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Hewan liar\",\"Kerbau\",\"Manusia\",\"Motor\",\"Truk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "# The value for class_mode in flow_from_dataframe MUST be 'raw' if you are attempting to do multilabel classification.\n",
    "train_gen = train_datagen.flow_from_dataframe(train, \n",
    "                                            x_col='Filename', \n",
    "                                            y_col=classes,\n",
    "                                            target_size=(224,224),\n",
    "                                            class_mode='raw',\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=True,\n",
    "                                            subset='training')\n",
    "val_gen = train_datagen.flow_from_dataframe(train,\n",
    "                                            x_col='Filename',\n",
    "                                            y_col=classes,\n",
    "                                            target_size=(224,224),\n",
    "                                            class_mode='raw',\n",
    "                                            batch_size=16,\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = test_datagen.flow_from_dataframe(test,\n",
    "                                            x_col='Filename',\n",
    "                                            # y_col=\"Label\",\n",
    "                                            batch_size=1,\n",
    "                                            shuffle=None,\n",
    "                                            seed=42,\n",
    "                                            target_size=(224,224),\n",
    "                                            class_mode=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives =K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "metrics = [\"accuracy\", \n",
    "           tf.keras.metrics.Recall(),\n",
    "           tf.keras.metrics.Precision(),\n",
    "           f1_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def tensorboard_callback(name):\n",
    "    logdir = os.path.join(\"Tensorboard/logs\", datetime.datetime.now().strftime(f\"%Y-%m-%d-{name}\"))\n",
    "    return TensorBoard(logdir)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, accuracy=0.9):\n",
    "        self.accuracy = accuracy\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get(\"val_accuracy\") > self.accuracy:\n",
    "            print(f\"\\nAkurasi telah mencapai {self.accuracy}%\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(model, name_model):\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(nrows=3,\n",
    "                                     ncols=1,\n",
    "                                     figsize=(15, 15))\n",
    "        ax1.plot(model.history[\"accuracy\"], marker=\".\")\n",
    "        ax1.plot(model.history[\"recall\"], marker=\".\") \n",
    "        ax1.plot(model.history[\"precision\"], marker=\".\")\n",
    "        ax1.plot(model.history[\"f1_score\"], marker=\".\")\n",
    "        ax1.set_xlabel(\"epochs\")\n",
    "        ax1.legend([\"accuracy\", \n",
    "        \"recall\", \n",
    "        \"precission\", \n",
    "        \"f1\"], loc=\"lower left\")\n",
    "        ax1.grid(True)\n",
    "        ax1.set_title(name_model + ' Training')\n",
    "        \n",
    "        ax2.plot(model.history[\"val_accuracy\"], marker=\".\")\n",
    "        ax2.plot(model.history[\"val_recall\"], marker=\".\") \n",
    "        ax2.plot(model.history[\"val_precision\"], marker=\".\")\n",
    "        ax2.plot(model.history[\"val_f1_score\"], marker=\".\")\n",
    "        ax2.set_xlabel(\"epochs\")\n",
    "        ax2.legend([\"val_accuracy\", \n",
    "                \"val_recall\", \n",
    "                \"val_precission\", \n",
    "                \"val_f1\"], loc=\"lower left\")\n",
    "        ax2.grid(True)\n",
    "        ax2.set_title(name_model + \" Val\")\n",
    "        \n",
    "        ax3.plot(model.history[\"loss\"])\n",
    "        ax3.plot(model.history[\"val_loss\"])\n",
    "        ax3.set_xlabel(\"epochs\")\n",
    "        ax3.legend([\"loss\", 'val_loss'])\n",
    "        ax3.grid(True)\n",
    "        ax3.set_title(name_model + \" Loss\")\n",
    "        fig.suptitle(name_model, fontsize=24)\n",
    "        return plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, name_file):\n",
    "    test_gen.reset()\n",
    "    pred = model.predict(test_gen,steps=test_gen.n // test_gen.batch_size, verbose=1)\n",
    "    pred_bool = (pred > 0.5)\n",
    "    predictions = pred_bool.astype(int)\n",
    "    columns=classes\n",
    "    #columns should be the same order of y_col\n",
    "    results = pd.DataFrame(predictions, columns=columns)\n",
    "    results[\"Filenames\"] = test_gen.filenames\n",
    "    ordered_cols=[\"Filenames\"]+columns\n",
    "    results=results[ordered_cols]\n",
    "    return results.to_csv(name_file, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visual confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test[classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visaul_confusion_matrix(y_true, y_pred):\n",
    "    mcm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "    print(mcm)\n",
    "# Display confusion matrices for each class\n",
    "    for i in range(len(classes)):\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=mcm[i], display_labels=[0, 1])\n",
    "        disp.plot(cmap='viridis', values_format='d')\n",
    "        plt.title(f'Confusion Matrix for {classes[i]}')\n",
    "    return plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet():\n",
    "    pre_trained_model = tf.keras.applications.resnet_v2.ResNet50V2(input_shape=(224, 224, 3),\n",
    "                                                        include_top=False,\n",
    "                                                        weights='imagenet')\n",
    "    \n",
    "    for layer in pre_trained_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    return pre_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = resnet.get_layer(\"post_relu\")\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_resnet(pre_trained_model, last_layer):\n",
    "    x = tf.keras.layers.Flatten()(last_layer)\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(5, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=pre_trained_model.input, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resNet50V2 = model_resnet(resnet, last_output)\n",
    "model_resNet50V2.compile(optimizer='adam', loss=\"binary_crossentropy\",\n",
    "                   metrics=metrics)\n",
    "model_resNet50V2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "        histori1 = model_resNet50V2.fit(train_gen,\n",
    "                              steps_per_epoch=train_gen.n // train_gen.batch_size,\n",
    "                              epochs=30,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_gen.n // val_gen.batch_size,\n",
    "                              callbacks=[tensorboard_callback(\"model_resNet50V2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(histori1, \"Model ResNet50V2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model_resNet50V2, \"model resNet50V2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predict_resnet = pd.read_csv(\"model resNet50V2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = dt_predict_resnet[classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visaul_confusion_matrix(y_true, y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Resnet101v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet101v2():\n",
    "    pre_train = tf.keras.applications.resnet_v2.ResNet101V2(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "    \n",
    "    for layer in pre_train.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    return pre_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet101v2 = resnet101v2()\n",
    "resnet101v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception ResnetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_resnetv2():\n",
    "    pre_trainded_model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(\n",
    "        input_shape = (224, 224, 3),\n",
    "        include_top = False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    for layer in pre_trainded_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    return pre_trainded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_resnetv2 = inception_resnetv2()\n",
    "inception_resnetv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inception_resnetv2(pre_trained_model, last_layer):\n",
    "    x = tf.keras.layers.Flatten()(last_layer)\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(5, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=pre_trained_model.input, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_inresnetv2 = inception_resnetv2.get_layer(\"conv_7b_ac\")\n",
    "last_output_inresnetv2 = last_layer_inresnetv2.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception_resnetv2 = model_inception_resnetv2(inception_resnetv2, last_output_inresnetv2)\n",
    "model_inception_resnetv2.compile(optimizer='adam', loss=\"binary_crossentropy\",\n",
    "                   metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception_resnetv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    history6 = model_inception_resnetv2.fit(train_gen,\n",
    "                              steps_per_epoch=train_gen.n // train_gen.batch_size,\n",
    "                              epochs=50,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_gen.n // val_gen.batch_size,\n",
    "                              callbacks=[tensorboard_callback(\"model_inception_resnetv2\"),\n",
    "                              myCallback(accuracy=0.95)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(history6, \"Model Inception-ResNetV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model_inception_resnetv2, \"model_inception_resnetv2.csv\")\n",
    "dt_model_inresnetv2 = pd.read_csv(\"model_inception_resnetv2.csv\")\n",
    "y_pred_6 = dt_model_inresnetv2[[\"Hewan liar\", \"Motor\", \"Kerbau\", \"Manusia\", \"Truk\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visaul_confusion_matrix(y_true, y_pred_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficienNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficienNet():\n",
    "    pre_trained_model = tf.keras.applications.efficientnet_v2.EfficientNetV2S(\n",
    "        input_shape=(224, 224, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    for layer in pre_trained_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return pre_trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficienNet = efficienNet()\n",
    "efficienNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer_efficientNet = efficienNet.get_layer(\"top_activation\")\n",
    "last_output_efficientNet = last_layer_efficientNet.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_efficientNet(pre_trained_model, last_layer):\n",
    "    x = tf.keras.layers.Flatten()(last_layer)\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(5, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=pre_trained_model.input, outputs=x)  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficienNet = final_efficientNet(efficienNet, last_output_efficientNet)\n",
    "model_efficienNet.compile(optimizer='adam', loss=\"binary_crossentropy\",\n",
    "                   metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficienNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    history5 = model_efficienNet.fit(train_gen,\n",
    "                              steps_per_epoch=train_gen.n // train_gen.batch_size,\n",
    "                              epochs=50,\n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=val_gen.n // val_gen.batch_size,\n",
    "                              callbacks=[tensorboard_callback(\"model_efficienNetV2S\"),\n",
    "                              myCallback(accuracy=0.95)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(history5, \"Model EfficienNetV2 Small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model_efficienNet, 'model efficienNet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model_efficenNet = pd.read_csv('model efficienNet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_5 = dt_model_efficenNet[[\"Hewan liar\", \"Motor\", \"Kerbau\", \"Manusia\", \"Truk\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visaul_confusion_matrix(y_true, y_pred_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Vis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_name(model):\n",
    "    outputs = [layer.outputs for layer in model.layer]\n",
    "    layer_name = []\n",
    "    for layer in outputs:\n",
    "        layer_name.append(layer.name.split(\"/\"))\n",
    "    \n",
    "    return layer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_intermediate_activations(layer_names, activations):\n",
    "    assert len(layer_names)==len(activations), \"Make sure layers and activation values match\"\n",
    "    images_per_row=16\n",
    "    \n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        nb_features = layer_activation.shape[-1]\n",
    "        size= layer_activation.shape[1]\n",
    "\n",
    "        nb_cols = nb_features // images_per_row\n",
    "        grid = np.zeros((size*nb_cols, size*images_per_row))\n",
    "\n",
    "        for col in range(nb_cols):\n",
    "            for row in range(images_per_row):\n",
    "                feature_map = layer_activation[0,:,:,col*images_per_row + row]\n",
    "                feature_map -= feature_map.mean()\n",
    "                feature_map /= feature_map.std()\n",
    "                feature_map *=255\n",
    "                feature_map = np.clip(feature_map, 0, 255).astype(np.uint8)\n",
    "\n",
    "                grid[col*size:(col+1)*size, row*size:(row+1)*size] = feature_map\n",
    "\n",
    "        scale = 1./size\n",
    "        plt.figure(figsize=(scale*grid.shape[1], scale*grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(grid, aspect='auto', cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visaul_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Grad Cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(dir, size):\n",
    "    img = keras.utils.load_img(dir, target_size=size)\n",
    "    array = keras.utils.img_to_array(img)\n",
    "    array = np.expand_dims(array)\n",
    "    return array\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = keras.models.Model(\n",
    "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
    "    # Load the original image\n",
    "    img = keras.utils.load_img(img_path)\n",
    "    img = keras.utils.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "\n",
    "    # Save the superimposed image\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Display Grad CAM\n",
    "    display(Image(cam_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
